{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import gensim\n",
    "from gensim.corpora import Dictionary\n",
    "from gensim import corpora, models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "docs = [\n",
    "    ['cat', 'dog', 'possum', 'wolf', 'rat'],  # topic 0\n",
    "    ['cat', 'possum', 'wolf', 'fox', 'rabbit', 'rat'],  # topic 0\n",
    "    ['tuna', 'whale', 'shark', 'salmon', 'stringray'],  # topic 1\n",
    "    ['tuna', 'shark', 'salmon', 'eel', 'stingray'],  # topic 1\n",
    "    ['pidgeon', 'hawk', 'sparrow', 'crow', 'parrot'],  # topic 2\n",
    "    ['pidgeon', 'crow', 'raven', 'parrot', 'eagle']   # topic 2\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(0, 'cat') (1, 'dog') (2, 'possum') (3, 'rat') (4, 'wolf') (5, 'fox') (6, 'rabbit') (7, 'salmon') (8, 'shark') (9, 'stringray') (10, 'tuna') (11, 'whale') (12, 'eel') (13, 'stingray') (14, 'crow') (15, 'hawk') (16, 'parrot') (17, 'pidgeon') (18, 'sparrow') (19, 'eagle') (20, 'raven')\n"
     ]
    }
   ],
   "source": [
    "dct = Dictionary(docs)\n",
    "print(' '.join('%s'%(i,) for i in dct.items()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[[(0, 1), (1, 1), (2, 1), (3, 1), (4, 1)],\n",
       " [(0, 1), (2, 1), (3, 1), (4, 1), (5, 1), (6, 1)],\n",
       " [(7, 1), (8, 1), (9, 1), (10, 1), (11, 1)],\n",
       " [(7, 1), (8, 1), (10, 1), (12, 1), (13, 1)],\n",
       " [(14, 1), (15, 1), (16, 1), (17, 1), (18, 1)],\n",
       " [(14, 1), (16, 1), (17, 1), (19, 1), (20, 1)]]"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "docs_bow = [dct.doc2bow(doc) for doc in docs]\n",
    "docs_bow"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "lda_model = gensim.models.LdaModel(docs_bow, num_topics=3, id2word=dct)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['cat', 'dog', 'possum', 'wolf', 'rat'] >>>>> [(0, 0.05577975), (1, 0.88824743), (2, 0.05597283)]\n",
      "['cat', 'possum', 'wolf', 'fox', 'rabbit', 'rat'] >>>>> [(0, 0.04783169), (1, 0.90415514), (2, 0.048013188)]\n",
      "['tuna', 'whale', 'shark', 'salmon', 'stringray'] >>>>> [(0, 0.05868661), (1, 0.05589025), (2, 0.8854231)]\n",
      "['tuna', 'shark', 'salmon', 'eel', 'stingray'] >>>>> [(0, 0.8647225), (1, 0.05618122), (2, 0.07909632)]\n",
      "['pidgeon', 'hawk', 'sparrow', 'crow', 'parrot'] >>>>> [(0, 0.8878725), (1, 0.055951286), (2, 0.05617614)]\n",
      "['pidgeon', 'crow', 'raven', 'parrot', 'eagle'] >>>>> [(0, 0.8878262), (1, 0.055959612), (2, 0.056214225)]\n"
     ]
    }
   ],
   "source": [
    "# Seems like all the documents are assigned to a single topic!\n",
    "for i, db in enumerate(docs_bow):\n",
    "    print(docs[i], '>>>>>', lda_model[db])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[(0,\n",
       "  '0.105*\"parrot\" + 0.104*\"crow\" + 0.104*\"pidgeon\" + 0.061*\"salmon\" + 0.061*\"shark\" + 0.060*\"tuna\" + 0.060*\"hawk\" + 0.060*\"stingray\" + 0.060*\"sparrow\" + 0.060*\"eel\"'),\n",
       " (1,\n",
       "  '0.127*\"cat\" + 0.127*\"possum\" + 0.127*\"wolf\" + 0.126*\"rat\" + 0.072*\"rabbit\" + 0.072*\"dog\" + 0.072*\"fox\" + 0.021*\"tuna\" + 0.020*\"salmon\" + 0.020*\"shark\"'),\n",
       " (2,\n",
       "  '0.108*\"tuna\" + 0.108*\"shark\" + 0.107*\"salmon\" + 0.107*\"whale\" + 0.107*\"stringray\" + 0.030*\"crow\" + 0.030*\"pidgeon\" + 0.030*\"rat\" + 0.030*\"raven\" + 0.029*\"wolf\"')]"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lda_model.print_topics()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Try TFIDF\n",
    "tfidf = models.TfidfModel(docs_bow)\n",
    "docs_tfidf = tfidf[docs_bow]\n",
    "tfidf_model = gensim.models.LdaMulticore(docs_tfidf, num_topics=3, id2word=dct)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['cat', 'dog', 'possum', 'wolf', 'rat'] >>>>> [(0, 0.056555387), (1, 0.88662046), (2, 0.056824137)]\n",
      "['cat', 'possum', 'wolf', 'fox', 'rabbit', 'rat'] >>>>> [(0, 0.04854632), (1, 0.9026757), (2, 0.048777964)]\n",
      "['tuna', 'whale', 'shark', 'salmon', 'stringray'] >>>>> [(0, 0.057446647), (1, 0.87425447), (2, 0.06829886)]\n",
      "['tuna', 'shark', 'salmon', 'eel', 'stingray'] >>>>> [(0, 0.056884717), (1, 0.060229216), (2, 0.8828861)]\n",
      "['pidgeon', 'hawk', 'sparrow', 'crow', 'parrot'] >>>>> [(0, 0.8869137), (1, 0.056311637), (2, 0.05677466)]\n",
      "['pidgeon', 'crow', 'raven', 'parrot', 'eagle'] >>>>> [(0, 0.8869467), (1, 0.05627355), (2, 0.056779798)]\n"
     ]
    }
   ],
   "source": [
    "# Finds 'birds' (topic 0) and 'animals' (topic 1), but wrongly assigns one of the 'sea creatures' doc to 'animals'.\n",
    "for i, db in enumerate(docs_bow):\n",
    "    print(docs[i], '>>>>>', tfidf_model[db])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[(0,\n",
       "  '0.073*\"shark\" + 0.072*\"tuna\" + 0.072*\"salmon\" + 0.065*\"stingray\" + 0.065*\"raven\" + 0.064*\"stringray\" + 0.064*\"eagle\" + 0.064*\"eel\" + 0.063*\"whale\" + 0.051*\"crow\"'),\n",
       " (1,\n",
       "  '0.097*\"dog\" + 0.075*\"cat\" + 0.074*\"wolf\" + 0.074*\"possum\" + 0.073*\"rat\" + 0.040*\"salmon\" + 0.039*\"tuna\" + 0.039*\"parrot\" + 0.038*\"crow\" + 0.038*\"whale\"'),\n",
       " (2,\n",
       "  '0.075*\"sparrow\" + 0.072*\"fox\" + 0.072*\"hawk\" + 0.070*\"rabbit\" + 0.058*\"parrot\" + 0.058*\"pidgeon\" + 0.057*\"crow\" + 0.056*\"cat\" + 0.056*\"rat\" + 0.056*\"wolf\"')]"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tfidf_model.print_topics()  # Looks better"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Running LDA with the same parameters produces different results. I.e. the documents are distributed\n",
    "# to different clusters\n",
    "# LDA2: cluster 0 = animals & sea creatures, cluster 1 = birds\n",
    "# LDA3: cluster 2 = animals, cluster 0 = sea creatures, cluster 1 = birds\n",
    "# LDA4: "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['cat', 'dog', 'possum', 'wolf', 'rat'] >>>>> [(0, 0.88830477), (1, 0.055536024), (2, 0.05615925)]\n",
      "['cat', 'possum', 'wolf', 'fox', 'rabbit', 'rat'] >>>>> [(0, 0.90415084), (1, 0.047622196), (2, 0.048226975)]\n",
      "['tuna', 'whale', 'shark', 'salmon', 'stringray'] >>>>> [(0, 0.8879269), (1, 0.05563086), (2, 0.056442298)]\n",
      "['tuna', 'shark', 'salmon', 'eel', 'stingray'] >>>>> [(0, 0.8879263), (1, 0.05564019), (2, 0.05643354)]\n",
      "['pidgeon', 'hawk', 'sparrow', 'crow', 'parrot'] >>>>> [(0, 0.055285085), (1, 0.88846135), (2, 0.056253582)]\n",
      "['pidgeon', 'crow', 'raven', 'parrot', 'eagle'] >>>>> [(0, 0.055278324), (1, 0.88870174), (2, 0.05601993)]\n"
     ]
    }
   ],
   "source": [
    "# Setting the alpha parameter for LDA makes it a lot better.\n",
    "lda_model2 = gensim.models.LdaModel(docs_bow, num_topics=3, id2word=dct, alpha=[0.33, 0.33, 0.33])\n",
    "\n",
    "# Seems like all the documents are assigned to a single topic!\n",
    "for i, db in enumerate(docs_bow):\n",
    "    print(docs[i], '>>>>>', lda_model2[db])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['cat', 'dog', 'possum', 'wolf', 'rat'] >>>>> [(0, 0.055462886), (1, 0.055627797), (2, 0.88890934)]\n",
      "['cat', 'possum', 'wolf', 'fox', 'rabbit', 'rat'] >>>>> [(0, 0.0475648), (1, 0.04772295), (2, 0.90471226)]\n",
      "['tuna', 'whale', 'shark', 'salmon', 'stringray'] >>>>> [(0, 0.88911754), (1, 0.055556968), (2, 0.0553255)]\n",
      "['tuna', 'shark', 'salmon', 'eel', 'stingray'] >>>>> [(0, 0.88913167), (1, 0.05554036), (2, 0.05532796)]\n",
      "['pidgeon', 'hawk', 'sparrow', 'crow', 'parrot'] >>>>> [(0, 0.055435132), (1, 0.88655597), (2, 0.058008883)]\n",
      "['pidgeon', 'crow', 'raven', 'parrot', 'eagle'] >>>>> [(0, 0.055749834), (1, 0.081180245), (2, 0.86306995)]\n"
     ]
    }
   ],
   "source": [
    "# Setting the alpha parameter for LDA makes it a lot better.\n",
    "lda_model3 = gensim.models.LdaModel(docs_bow, num_topics=3, id2word=dct, alpha=[0.33, 0.33, 0.33])\n",
    "\n",
    "# Seems like all the documents are assigned to a single topic!\n",
    "for i, db in enumerate(docs_bow):\n",
    "    print(docs[i], '>>>>>', lda_model3[db])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['cat', 'dog', 'possum', 'wolf', 'rat'] >>>>> [(0, 0.055444412), (1, 0.88919723), (2, 0.055358402)]\n",
      "['cat', 'possum', 'wolf', 'fox', 'rabbit', 'rat'] >>>>> [(0, 0.04753296), (1, 0.9050161), (2, 0.04745087)]\n",
      "['tuna', 'whale', 'shark', 'salmon', 'stringray'] >>>>> [(0, 0.8882601), (1, 0.05539308), (2, 0.056346808)]\n",
      "['tuna', 'shark', 'salmon', 'eel', 'stingray'] >>>>> [(0, 0.88526106), (1, 0.055563055), (2, 0.059175946)]\n",
      "['pidgeon', 'hawk', 'sparrow', 'crow', 'parrot'] >>>>> [(0, 0.05552601), (1, 0.055446446), (2, 0.8890276)]\n",
      "['pidgeon', 'crow', 'raven', 'parrot', 'eagle'] >>>>> [(0, 0.055518735), (1, 0.055454127), (2, 0.8890271)]\n"
     ]
    }
   ],
   "source": [
    "# Setting the alpha parameter for LDA makes it a lot better.\n",
    "lda_model4 = gensim.models.LdaModel(docs_bow, num_topics=3, id2word=dct, alpha=[0.33, 0.33, 0.33])\n",
    "\n",
    "# Seems like all the documents are assigned to a single topic!\n",
    "for i, db in enumerate(docs_bow):\n",
    "    print(docs[i], '>>>>>', lda_model4[db])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['cat', 'dog', 'possum', 'wolf', 'rat'] >>>>> [(0, 0.055993363), (1, 0.8886343), (2, 0.055372357)]\n",
      "['cat', 'possum', 'wolf', 'fox', 'rabbit', 'rat'] >>>>> [(0, 0.048065916), (1, 0.90445805), (2, 0.047475997)]\n",
      "['tuna', 'whale', 'shark', 'salmon', 'stringray'] >>>>> [(0, 0.05614015), (1, 0.05539772), (2, 0.8884621)]\n",
      "['tuna', 'shark', 'salmon', 'eel', 'stingray'] >>>>> [(0, 0.05617918), (1, 0.05540006), (2, 0.88842076)]\n",
      "['pidgeon', 'hawk', 'sparrow', 'crow', 'parrot'] >>>>> [(0, 0.056796912), (1, 0.8809422), (2, 0.06226087)]\n",
      "['pidgeon', 'crow', 'raven', 'parrot', 'eagle'] >>>>> [(0, 0.056672018), (1, 0.061162397), (2, 0.88216555)]\n"
     ]
    }
   ],
   "source": [
    "# Setting the alpha parameter for LDA makes it a lot better.\n",
    "lda_model5 = gensim.models.LdaModel(docs_bow, num_topics=3, id2word=dct, alpha=[0.33, 0.33, 0.33])\n",
    "\n",
    "# Seems like all the documents are assigned to a single topic!\n",
    "for i, db in enumerate(docs_bow):\n",
    "    print(docs[i], '>>>>>', lda_model5[db])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Now trying this using NMF\n",
    "# https://scikit-learn.org/stable/auto_examples/applications/plot_topics_extraction_with_nmf_lda.html#sphx-glr-auto-examples-applications-plot-topics-extraction-with-nmf-lda-py\n",
    "\n",
    "text_docs = [' '.join(e for e in d) for d in docs]\n",
    "\n",
    "text_docs\n",
    "\n",
    "tfidf = tfidf_vectorizer.fit_transform(text_docs)\n",
    "cv = count_vectorizer.fit_transform(text_docs)\n",
    "\n",
    "\n",
    "tfidf.toarray()\n",
    "\n",
    "cv.toarray()\n",
    "\n",
    "tfidf_transformer = TfidfTransformer()\n",
    "\n",
    "tfidf_v = tfidf_transformer.fit_transform(cv)\n",
    "\n",
    "tfidf_v.toarray()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['cat dog possum wolf rat',\n",
       " 'cat possum wolf fox rabbit rat',\n",
       " 'tuna whale shark salmon stringray',\n",
       " 'tuna shark salmon eel stingray',\n",
       " 'pidgeon hawk sparrow crow parrot',\n",
       " 'pidgeon crow raven parrot eagle']"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "text_docs = [' '.join(e for e in d) for d in docs]\n",
    "\n",
    "text_docs\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Try using TFIDF\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer, CountVectorizer, TfidfTransformer\n",
    "\n",
    "tfidf_vectorizer = TfidfVectorizer(#max_df=1, min_df=0,\n",
    "                                   #max_features=3,  # Ha! this was causing the problems!\n",
    "                                   stop_words='english')\n",
    "\n",
    "tfidf = tfidf_vectorizer.fit_transform(text_docs)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<6x21 sparse matrix of type '<class 'numpy.float64'>'\n",
       "\twith 31 stored elements in Compressed Sparse Row format>"
      ]
     },
     "execution_count": 55,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tfidf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0.42690011, 0.        , 0.5206008 , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.42690011,\n",
       "        0.        , 0.42690011, 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.42690011],\n",
       "       [0.37865978, 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.46177217, 0.        , 0.        , 0.        , 0.37865978,\n",
       "        0.46177217, 0.37865978, 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.37865978],\n",
       "       [0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.40912489, 0.40912489,\n",
       "        0.        , 0.        , 0.49892408, 0.40912489, 0.49892408,\n",
       "        0.        ],\n",
       "       [0.        , 0.        , 0.        , 0.        , 0.49892408,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.40912489, 0.40912489,\n",
       "        0.        , 0.49892408, 0.        , 0.40912489, 0.        ,\n",
       "        0.        ],\n",
       "       [0.        , 0.40912489, 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.49892408, 0.40912489, 0.40912489, 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.49892408, 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        ],\n",
       "       [0.        , 0.40912489, 0.        , 0.49892408, 0.        ,\n",
       "        0.        , 0.        , 0.40912489, 0.40912489, 0.        ,\n",
       "        0.        , 0.        , 0.49892408, 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        ]])"
      ]
     },
     "execution_count": 56,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tfidf.toarray()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['cat',\n",
       " 'crow',\n",
       " 'dog',\n",
       " 'eagle',\n",
       " 'eel',\n",
       " 'fox',\n",
       " 'hawk',\n",
       " 'parrot',\n",
       " 'pidgeon',\n",
       " 'possum',\n",
       " 'rabbit',\n",
       " 'rat',\n",
       " 'raven',\n",
       " 'salmon',\n",
       " 'shark',\n",
       " 'sparrow',\n",
       " 'stingray',\n",
       " 'stringray',\n",
       " 'tuna',\n",
       " 'whale',\n",
       " 'wolf']"
      ]
     },
     "execution_count": 57,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tfidf_vectorizer.get_feature_names()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "TfidfVectorizer(analyzer='word', binary=False, decode_error='strict',\n",
       "        dtype=<class 'numpy.int64'>, encoding='utf-8', input='content',\n",
       "        lowercase=True, max_df=1.0, max_features=3, min_df=1,\n",
       "        ngram_range=(1, 1), norm='l2', preprocessor=None, smooth_idf=True,\n",
       "        stop_words='english', strip_accents=None, sublinear_tf=False,\n",
       "        token_pattern='(?u)\\\\b\\\\w\\\\w+\\\\b', tokenizer=None, use_idf=True,\n",
       "        vocabulary=None)"
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tfidf_vectorizer.fit(text_docs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'cat': 0,\n",
       " 'dog': 2,\n",
       " 'possum': 9,\n",
       " 'wolf': 20,\n",
       " 'rat': 11,\n",
       " 'fox': 5,\n",
       " 'rabbit': 10,\n",
       " 'tuna': 18,\n",
       " 'whale': 19,\n",
       " 'shark': 14,\n",
       " 'salmon': 13,\n",
       " 'stringray': 17,\n",
       " 'eel': 4,\n",
       " 'stingray': 16,\n",
       " 'pidgeon': 8,\n",
       " 'hawk': 6,\n",
       " 'sparrow': 15,\n",
       " 'crow': 1,\n",
       " 'parrot': 7,\n",
       " 'raven': 12,\n",
       " 'eagle': 3}"
      ]
     },
     "execution_count": 58,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tfidf_vectorizer.vocabulary_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Also try it out step by step.\n",
    "# First just get a count of the words.\n",
    "count_vectorizer = CountVectorizer()\n",
    "cv = count_vectorizer.fit_transform(text_docs)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[1, 0, 1, 0, 0, 0, 0, 0, 0, 1, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 1],\n",
       "       [1, 0, 0, 0, 0, 1, 0, 0, 0, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 1],\n",
       "       [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 0, 0, 1, 1, 1, 0],\n",
       "       [0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 0, 1, 0, 1, 0, 0],\n",
       "       [0, 1, 0, 0, 0, 0, 1, 1, 1, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0],\n",
       "       [0, 1, 0, 1, 0, 0, 0, 1, 1, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0]],\n",
       "      dtype=int64)"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cv.toarray()\n",
    "# Ok the counts look good."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0.42690011, 0.        , 0.5206008 , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.42690011,\n",
       "        0.        , 0.42690011, 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.42690011],\n",
       "       [0.37865978, 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.46177217, 0.        , 0.        , 0.        , 0.37865978,\n",
       "        0.46177217, 0.37865978, 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.37865978],\n",
       "       [0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.40912489, 0.40912489,\n",
       "        0.        , 0.        , 0.49892408, 0.40912489, 0.49892408,\n",
       "        0.        ],\n",
       "       [0.        , 0.        , 0.        , 0.        , 0.49892408,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.40912489, 0.40912489,\n",
       "        0.        , 0.49892408, 0.        , 0.40912489, 0.        ,\n",
       "        0.        ],\n",
       "       [0.        , 0.40912489, 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.49892408, 0.40912489, 0.40912489, 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.49892408, 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        ],\n",
       "       [0.        , 0.40912489, 0.        , 0.49892408, 0.        ,\n",
       "        0.        , 0.        , 0.40912489, 0.40912489, 0.        ,\n",
       "        0.        , 0.        , 0.49892408, 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        ]])"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tfidf_transformer = TfidfTransformer()\n",
    "\n",
    "tfidf_v = tfidf_transformer.fit_transform(cv)\n",
    "\n",
    "tfidf_v.toarray()\n",
    "# Not sure how the below tf-idf terms are calculated!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TF:  0.2\n",
      "IDF using ln: 1.0986122886681098  then TF*IDF:  0.21972245773362198\n",
      "IDF using base10:  1.4771212547196624  then TF*IDF:  0.2954242509439325\n",
      "IDF using doc formula:  1.3679767852945943  then TF*IDF:  0.27359535705891885\n"
     ]
    }
   ],
   "source": [
    "# manual tf-idf calculation for the first word. \n",
    "# Unsure how above is done, probably using some different normalization for idf.\n",
    "# But relatively they look ok.\n",
    "import math\n",
    "_tf = (1.0/5)\n",
    "_idf = math.log(6.0/2, math.e)\n",
    "_idf2 = math.log(6.0/2, 10) + 1\n",
    "_idf3 = math.log(((1+6)/(2+1)), 10) + 1\n",
    "print('TF: ', _tf)\n",
    "print('IDF using ln:', _idf, ' then TF*IDF: ', _tf*_idf)\n",
    "print('IDF using base10: ', _idf2, ' then TF*IDF: ', _tf*_idf2)\n",
    "print('IDF using doc formula: ', _idf3, ' then TF*IDF: ', _tf*_idf3)\n",
    "\n",
    "# Ah. The exact details are in the documentation. There is normalization as well.\n",
    "# https://scikit-learn.org/stable/modules/feature_extraction.html#text-feature-extraction\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[1.84729786, 0.        , 2.25276297, 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.        , 1.84729786,\n",
       "        0.        , 1.84729786, 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        1.84729786],\n",
       "       [1.84729786, 0.        , 0.        , 0.        , 0.        ,\n",
       "        2.25276297, 0.        , 0.        , 0.        , 1.84729786,\n",
       "        2.25276297, 1.84729786, 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        1.84729786],\n",
       "       [0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        , 1.84729786, 1.84729786,\n",
       "        0.        , 0.        , 2.25276297, 1.84729786, 2.25276297,\n",
       "        0.        ],\n",
       "       [0.        , 0.        , 0.        , 0.        , 2.25276297,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        , 1.84729786, 1.84729786,\n",
       "        0.        , 2.25276297, 0.        , 1.84729786, 0.        ,\n",
       "        0.        ],\n",
       "       [0.        , 1.84729786, 0.        , 0.        , 0.        ,\n",
       "        0.        , 2.25276297, 1.84729786, 1.84729786, 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        2.25276297, 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        ],\n",
       "       [0.        , 1.84729786, 0.        , 2.25276297, 0.        ,\n",
       "        0.        , 0.        , 1.84729786, 1.84729786, 0.        ,\n",
       "        0.        , 0.        , 2.25276297, 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        ]])"
      ]
     },
     "execution_count": 59,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Try without any normalization.\n",
    "tfidf_transformer2 = TfidfTransformer(norm=None)\n",
    "tfidf_v2 = tfidf_transformer2.fit_transform(cv)\n",
    "tfidf_v2.toarray()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Hmmm ok leave this for now. Need to read the documentation more."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Use NMF to see if can get the documents classified into 3 correct topics.\n",
    "# References:\n",
    "# https://machinelearningmastery.com/introduction-to-matrix-decompositions-for-machine-learning/\n",
    "# https://stackoverflow.com/questions/39367597/how-to-deal-with-missing-values-in-python-scikit-nmf\n",
    "# https://scikit-learn.org/stable/modules/generated/sklearn.decomposition.NMF.html#sklearn.decomposition.NMF\n",
    "from sklearn.decomposition import NMF\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [],
   "source": [
    "nmf = NMF(n_components=3)\n",
    "nmf_v = nmf.fit_transform(tfidf_v)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[8.00999056e-01, 0.00000000e+00, 0.00000000e+00],\n",
       "       [8.00999056e-01, 0.00000000e+00, 0.00000000e+00],\n",
       "       [0.00000000e+00, 7.01689253e-01, 0.00000000e+00],\n",
       "       [0.00000000e+00, 7.01689253e-01, 7.40228630e-18],\n",
       "       [0.00000000e+00, 0.00000000e+00, 6.81305492e-01],\n",
       "       [0.00000000e+00, 0.00000000e+00, 6.81305492e-01]])"
      ]
     },
     "execution_count": 81,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "nmf_v  # a little hard to read"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0.8 , 0.  , 0.  ],\n",
       "       [0.8 , 0.  , 0.  ],\n",
       "       [0.  , 0.71, 0.  ],\n",
       "       [0.  , 0.71, 0.  ],\n",
       "       [0.  , 0.  , 0.67],\n",
       "       [0.  , 0.  , 0.67]])"
      ]
     },
     "execution_count": 75,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.round(nmf_v, 2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Nice!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(6, 21)"
      ]
     },
     "execution_count": 68,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tfidf_v.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(6, 3)"
      ]
     },
     "execution_count": 69,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 6 x 3 . 3 x 21\n",
    "nmf_v.shape\n",
    "# So I have the 6x3 (nmf_v), where is the 3x21? I.e. the word embeddings?\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(3, 21)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([[0.5 , 0.  , 0.  ],\n",
       "       [0.  , 0.  , 0.61],\n",
       "       [0.32, 0.  , 0.  ],\n",
       "       [0.  , 0.  , 0.37],\n",
       "       [0.  , 0.35, 0.  ],\n",
       "       [0.29, 0.  , 0.  ],\n",
       "       [0.  , 0.  , 0.37],\n",
       "       [0.  , 0.  , 0.61],\n",
       "       [0.  , 0.  , 0.61],\n",
       "       [0.5 , 0.  , 0.  ],\n",
       "       [0.29, 0.  , 0.  ],\n",
       "       [0.5 , 0.  , 0.  ],\n",
       "       [0.  , 0.  , 0.37],\n",
       "       [0.  , 0.57, 0.  ],\n",
       "       [0.  , 0.57, 0.  ],\n",
       "       [0.  , 0.  , 0.37],\n",
       "       [0.  , 0.35, 0.  ],\n",
       "       [0.  , 0.35, 0.  ],\n",
       "       [0.  , 0.57, 0.  ],\n",
       "       [0.  , 0.35, 0.  ],\n",
       "       [0.5 , 0.  , 0.  ]])"
      ]
     },
     "execution_count": 78,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print(nmf.components_.shape)\n",
    "np.round(nmf.components_.transpose(), 2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[1, 0, 1, 0, 0, 0, 0, 0, 0, 1, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 1],\n",
       "       [1, 0, 0, 0, 0, 1, 0, 0, 0, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 1],\n",
       "       [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 0, 0, 1, 1, 1, 0],\n",
       "       [0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 0, 1, 0, 1, 0, 0],\n",
       "       [0, 1, 0, 0, 0, 0, 1, 1, 1, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0],\n",
       "       [0, 1, 0, 1, 0, 0, 0, 1, 1, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0]],\n",
       "      dtype=int64)"
      ]
     },
     "execution_count": 91,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cv.toarray()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Actually we should just try NMF without TFIDF\n",
    "nmf2 = NMF(n_components=3)\n",
    "nmf_v2 = nmf2.fit_transform(cv)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[1.16, 0.  , 0.  ],\n",
       "       [1.32, 0.  , 0.  ],\n",
       "       [0.  , 1.17, 0.  ],\n",
       "       [0.  , 1.17, 0.  ],\n",
       "       [0.  , 0.  , 1.21],\n",
       "       [0.  , 0.  , 1.21]])"
      ]
     },
     "execution_count": 84,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.round(nmf_v2, 2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0.8 , 0.  , 0.  ],\n",
       "       [0.  , 0.  , 0.83],\n",
       "       [0.38, 0.  , 0.  ],\n",
       "       [0.  , 0.  , 0.41],\n",
       "       [0.  , 0.43, 0.  ],\n",
       "       [0.43, 0.  , 0.  ],\n",
       "       [0.  , 0.  , 0.41],\n",
       "       [0.  , 0.  , 0.83],\n",
       "       [0.  , 0.  , 0.83],\n",
       "       [0.8 , 0.  , 0.  ],\n",
       "       [0.43, 0.  , 0.  ],\n",
       "       [0.8 , 0.  , 0.  ],\n",
       "       [0.  , 0.  , 0.41],\n",
       "       [0.  , 0.86, 0.  ],\n",
       "       [0.  , 0.86, 0.  ],\n",
       "       [0.  , 0.  , 0.41],\n",
       "       [0.  , 0.43, 0.  ],\n",
       "       [0.  , 0.43, 0.  ],\n",
       "       [0.  , 0.86, 0.  ],\n",
       "       [0.  , 0.43, 0.  ],\n",
       "       [0.8 , 0.  , 0.  ]])"
      ]
     },
     "execution_count": 85,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.round(nmf2.components_.transpose(), 2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0.93, 0.  , 0.44, 0.  , 0.  , 0.5 , 0.  , 0.  , 0.  , 0.93, 0.5 ,\n",
       "        0.93, 0.  , 0.  , 0.  , 0.  , 0.  , 0.  , 0.  , 0.  , 0.93],\n",
       "       [1.06, 0.  , 0.5 , 0.  , 0.  , 0.56, 0.  , 0.  , 0.  , 1.06, 0.56,\n",
       "        1.06, 0.  , 0.  , 0.  , 0.  , 0.  , 0.  , 0.  , 0.  , 1.06],\n",
       "       [0.  , 0.  , 0.  , 0.  , 0.5 , 0.  , 0.  , 0.  , 0.  , 0.  , 0.  ,\n",
       "        0.  , 0.  , 1.  , 1.  , 0.  , 0.5 , 0.5 , 1.  , 0.5 , 0.  ],\n",
       "       [0.  , 0.  , 0.  , 0.  , 0.5 , 0.  , 0.  , 0.  , 0.  , 0.  , 0.  ,\n",
       "        0.  , 0.  , 1.  , 1.  , 0.  , 0.5 , 0.5 , 1.  , 0.5 , 0.  ],\n",
       "       [0.  , 1.  , 0.  , 0.5 , 0.  , 0.  , 0.5 , 1.  , 1.  , 0.  , 0.  ,\n",
       "        0.  , 0.5 , 0.  , 0.  , 0.5 , 0.  , 0.  , 0.  , 0.  , 0.  ],\n",
       "       [0.  , 1.  , 0.  , 0.5 , 0.  , 0.  , 0.5 , 1.  , 1.  , 0.  , 0.  ,\n",
       "        0.  , 0.5 , 0.  , 0.  , 0.5 , 0.  , 0.  , 0.  , 0.  , 0.  ]])"
      ]
     },
     "execution_count": 87,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Just to check :)\n",
    "np.round(np.dot(nmf_v2, nmf2.components_), 2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
